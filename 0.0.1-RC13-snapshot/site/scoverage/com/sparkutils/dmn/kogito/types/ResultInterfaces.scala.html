<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/dmn/kogito/types/ResultInterfaces.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils.dmn.kogito.types
</span>2 <span style=''>
</span>3 <span style=''>import com.sparkutils.dmn.DMNException
</span>4 <span style=''>import com.sparkutils.dmn.kogito.types.Arrays.exprCode
</span>5 <span style=''>import org.apache.spark.sql.catalyst.InternalRow
</span>6 <span style=''>import org.apache.spark.sql.catalyst.expressions.GenericInternalRow
</span>7 <span style=''>import org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper
</span>8 <span style=''>import org.apache.spark.sql.catalyst.expressions.codegen.{CodeGenerator, CodegenContext, ExprCode}
</span>9 <span style=''>import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, DateTimeUtils, GenericArrayData}
</span>10 <span style=''>import org.apache.spark.sql.types.{ArrayType, BinaryType, BooleanType, ByteType, DataType, DateType, Decimal, DecimalType, DoubleType, FloatType, IntegerType, LongType, MapType, ShortType, StringType, StructType, TimestampType}
</span>11 <span style=''>import org.apache.spark.unsafe.types.UTF8String
</span>12 <span style=''>
</span>13 <span style=''>import java.time.{LocalDate, LocalDateTime}
</span>14 <span style=''>import java.util
</span>15 <span style=''>import scala.collection.JavaConverters._
</span>16 <span style=''>import scala.reflect.{ClassTag, classTag}
</span>17 <span style=''>
</span>18 <span style=''>/**
</span>19 <span style=''> * Reverse the logic from ContextInterfaces
</span>20 <span style=''> */
</span>21 <span style=''>object ResultInterfaces {
</span>22 <span style=''>
</span>23 <span style=''>  val evalStatusEnding = </span><span style='background: #AEF1AE'>&quot;_dmnEvalStatus&quot;</span><span style=''>
</span>24 <span style=''>
</span>25 <span style=''>  // The errors in intellij are not real
</span>26 <span style=''>  val NOT_FOUND: Byte = </span><span style='background: #AEF1AE'>-6.toByte</span><span style=''> // DDL has a decision which isn't in the DMN, possibly a typo or the dmn decision was removed / not there yet
</span>27 <span style=''>  val NOT_EVALUATED: Byte = </span><span style='background: #AEF1AE'>-5.toByte</span><span style=''> // shouldn't happen
</span>28 <span style=''>  val EVALUATING: Byte = </span><span style='background: #AEF1AE'>-4.toByte</span><span style=''> // shouldn't happen as it'll be overwritten in KogitoDDLResult
</span>29 <span style=''>  val SUCCEEDED: Byte  = </span><span style='background: #AEF1AE'>1.toByte</span><span style=''>
</span>30 <span style=''>  val SKIPPED_WARN: Byte  = </span><span style='background: #AEF1AE'>-3.toByte</span><span style=''>
</span>31 <span style=''>  val SKIPPED_ERROR: Byte  = </span><span style='background: #AEF1AE'>-2.toByte</span><span style=''>
</span>32 <span style=''>  val FAILED: Byte  = </span><span style='background: #AEF1AE'>0.toByte</span><span style=''>
</span>33 <span style=''>
</span>34 <span style=''>  trait Getter {
</span>35 <span style=''>    def get(path: Any): Any
</span>36 <span style=''>  }
</span>37 <span style=''>
</span>38 <span style=''>  def forType(dataType: DataType): Getter = dataType match {
</span>39 <span style=''>    case structType: StructType </span><span style='background: #AEF1AE'>=&gt;
</span>40 <span style=''></span><span style='background: #AEF1AE'>
</span>41 <span style=''></span><span style='background: #AEF1AE'>      val s = structType.fields.map { f =&gt;
</span>42 <span style=''></span><span style='background: #AEF1AE'>        (f.name,
</span>43 <span style=''></span><span style='background: #AEF1AE'>          if (f.name.endsWith(evalStatusEnding))
</span>44 <span style=''></span><span style='background: #AEF1AE'>            ((path: Any) =&gt; EVALUATING): Getter
</span>45 <span style=''></span><span style='background: #AEF1AE'>          else
</span>46 <span style=''></span><span style='background: #AEF1AE'>            forType(f.dataType)
</span>47 <span style=''></span><span style='background: #AEF1AE'>        )
</span>48 <span style=''></span><span style='background: #AEF1AE'>      }
</span>49 <span style=''></span><span style='background: #AEF1AE'>
</span>50 <span style=''></span><span style='background: #AEF1AE'>      (path: Any) =&gt; {
</span>51 <span style=''></span><span style='background: #AEF1AE'>        if (path == null) </span><span style='background: #F0ADAD'>null</span><span style='background: #AEF1AE'> else {
</span>52 <span style=''></span><span style='background: #AEF1AE'>          val m = path.asInstanceOf[util.Map[String, Object]]
</span>53 <span style=''></span><span style='background: #AEF1AE'>          InternalRow(s.map { case (name, g) =&gt; g.get(m.get(name)) }: _*)
</span>54 <span style=''></span><span style='background: #AEF1AE'>        }
</span>55 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>56 <span style=''>    case StringType =&gt; </span><span style='background: #AEF1AE'>(path: Any) =&gt; if (path == null) null else UTF8String.fromString( path.toString )</span><span style=''>
</span>57 <span style=''>    case IntegerType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else path.asInstanceOf[Integer]</span><span style=''>
</span>58 <span style=''>    case LongType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else path.asInstanceOf[Long]</span><span style=''>
</span>59 <span style=''>    case BooleanType =&gt; </span><span style='background: #AEF1AE'>(path: Any) =&gt; if (path == null) </span><span style='background: #F0ADAD'>null</span><span style='background: #AEF1AE'> else path.asInstanceOf[Boolean]</span><span style=''>
</span>60 <span style=''>    case DoubleType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else path.asInstanceOf[Double]</span><span style=''>
</span>61 <span style=''>    case FloatType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else path.asInstanceOf[Float]</span><span style=''>
</span>62 <span style=''>    case BinaryType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else path.asInstanceOf[Array[Byte]]</span><span style=''>
</span>63 <span style=''>    case ByteType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else path.asInstanceOf[Byte]</span><span style=''>
</span>64 <span style=''>    case ShortType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else path.asInstanceOf[Short]</span><span style=''>
</span>65 <span style=''>    case DateType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else DateTimeUtils.localDateToDays( path.asInstanceOf[LocalDate] )</span><span style=''>
</span>66 <span style=''>    case TimestampType =&gt; </span><span style='background: #F0ADAD'>(path: Any) =&gt; if (path == null) null else DateTimeUtils.localDateTimeToMicros( path.asInstanceOf[LocalDateTime] )</span><span style=''>
</span>67 <span style=''>    case _: DecimalType =&gt; </span><span style='background: #AEF1AE'>(path: Any) =&gt;
</span>68 <span style=''></span><span style='background: #AEF1AE'>      if (path == null) </span><span style='background: #F0ADAD'>null</span><span style='background: #AEF1AE'> else Decimal.apply(path.asInstanceOf[java.math.BigDecimal])</span><span style=''>
</span>69 <span style=''>    case ArrayType(typ, _) </span><span style='background: #AEF1AE'>=&gt;
</span>70 <span style=''></span><span style='background: #AEF1AE'>      val g = forType(typ)
</span>71 <span style=''></span><span style='background: #AEF1AE'>      (path: Any) =&gt; {
</span>72 <span style=''></span><span style='background: #AEF1AE'>        if (path == null) </span><span style='background: #F0ADAD'>null</span><span style='background: #AEF1AE'> else {
</span>73 <span style=''></span><span style='background: #AEF1AE'>          val a = path.asInstanceOf[util.List[_]].toArray.map(g.get(_))
</span>74 <span style=''></span><span style='background: #AEF1AE'>          new GenericArrayData(a)
</span>75 <span style=''></span><span style='background: #AEF1AE'>        }
</span>76 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>77 <span style=''>    case MapType(k, v, _) </span><span style='background: #AEF1AE'>=&gt;
</span>78 <span style=''></span><span style='background: #AEF1AE'>      val kG = forType(k)
</span>79 <span style=''></span><span style='background: #AEF1AE'>      val vG = forType(v)
</span>80 <span style=''></span><span style='background: #AEF1AE'>      (path: Any) =&gt; {
</span>81 <span style=''></span><span style='background: #AEF1AE'>        if (path == null) </span><span style='background: #F0ADAD'>null</span><span style='background: #AEF1AE'> else {
</span>82 <span style=''></span><span style='background: #AEF1AE'>          val m = path.asInstanceOf[util.Map[Object, Object]].asScala.toMap.map(e =&gt; kG.get(e._1) -&gt; vG.get(e._2))
</span>83 <span style=''></span><span style='background: #AEF1AE'>          new ArrayBasedMapData(new GenericArrayData(m.keys.toArray), new GenericArrayData(m.values.toArray))
</span>84 <span style=''></span><span style='background: #AEF1AE'>        }
</span>85 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>86 <span style=''>    case _ =&gt; </span><span style='background: #F0ADAD'>throw new DMNException(s&quot;Could not load Kogito Result Provider for dataType $dataType&quot;)</span><span style=''>
</span>87 <span style=''>  }
</span>88 <span style=''>
</span>89 <span style=''>  trait GetterCodeGen extends Serializable {
</span>90 <span style=''>    /**
</span>91 <span style=''>     * Generate code for this path, object casting and input null checking will be added by the caller
</span>92 <span style=''>     * @param ctx
</span>93 <span style=''>     * @param pathName variable to access (typically a SpecializedGetters)
</span>94 <span style=''>     * @return generated code which returns either the underlying type or util.map/util.list
</span>95 <span style=''>     */
</span>96 <span style=''>    def forPath(ctx: CodegenContext, pathName: String, pathNameIsNull: String): ExprCode
</span>97 <span style=''>  }
</span>98 <span style=''>  def nullOr[T: ClassTag](f: String =&gt; String = path =&gt; s&quot;$path&quot;): GetterCodeGen =
</span>99 <span style=''>    (ctx: CodegenContext, pathName: String, pathNameIsNull: String) =&gt; {
</span>100 <span style=''>      val c = </span><span style='background: #AEF1AE'>f(pathName)</span><span style=''>
</span>101 <span style=''>      </span><span style='background: #AEF1AE'>exprCode(classTag[T].runtimeClass, ctx,
</span>102 <span style=''></span><span style='background: #AEF1AE'>        code&quot;&quot;&quot;(($pathNameIsNull) ? null : $c);&quot;&quot;&quot;, cast = false)</span><span style=''> // all are object anyway
</span>103 <span style=''>    }
</span>104 <span style=''>
</span>105 <span style=''>  def forTypeCodeGen(dataType: DataType): GetterCodeGen = dataType match {
</span>106 <span style=''>   case structType: StructType =&gt;
</span>107 <span style=''>      </span><span style='background: #AEF1AE'>(ctx: CodegenContext, pathName: String, pathNameIsNull: String) =&gt; {
</span>108 <span style=''></span><span style='background: #AEF1AE'>        val expr = exprCode(classOf[GenericInternalRow],ctx)
</span>109 <span style=''></span><span style='background: #AEF1AE'>
</span>110 <span style=''></span><span style='background: #AEF1AE'>        val mapName = ctx.freshVariable(&quot;map&quot;, classOf[util.Map[String,Object]])
</span>111 <span style=''></span><span style='background: #AEF1AE'>
</span>112 <span style=''></span><span style='background: #AEF1AE'>        val s = structType.fields.map { f =&gt;
</span>113 <span style=''></span><span style='background: #AEF1AE'>          (f.name,
</span>114 <span style=''></span><span style='background: #AEF1AE'>            if (f.name.endsWith(evalStatusEnding))
</span>115 <span style=''></span><span style='background: #AEF1AE'>              nullOr[Byte](_ =&gt; s&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;)
</span>116 <span style=''></span><span style='background: #AEF1AE'>            else
</span>117 <span style=''></span><span style='background: #AEF1AE'>              forTypeCodeGen(f.dataType)
</span>118 <span style=''></span><span style='background: #AEF1AE'>          )
</span>119 <span style=''></span><span style='background: #AEF1AE'>        }.map{
</span>120 <span style=''></span><span style='background: #AEF1AE'>          case (n,f) =&gt;
</span>121 <span style=''></span><span style='background: #AEF1AE'>            f.forPath(ctx, s&quot;&quot;&quot;$mapName.get(&quot;$n&quot;)&quot;&quot;&quot;, expr.isNull)
</span>122 <span style=''></span><span style='background: #AEF1AE'>        }
</span>123 <span style=''></span><span style='background: #AEF1AE'>        val init = s.foldLeft(code&quot;&quot;){
</span>124 <span style=''></span><span style='background: #AEF1AE'>          case (c, e) =&gt;
</span>125 <span style=''></span><span style='background: #AEF1AE'>            code&quot;&quot;&quot;$c
</span>126 <span style=''></span><span style='background: #AEF1AE'>                ${e.code}
</span>127 <span style=''></span><span style='background: #AEF1AE'>                &quot;&quot;&quot;
</span>128 <span style=''></span><span style='background: #AEF1AE'>        }
</span>129 <span style=''></span><span style='background: #AEF1AE'>        val fields = s.map(_.value).mkString(&quot;\n,&quot;)
</span>130 <span style=''></span><span style='background: #AEF1AE'>
</span>131 <span style=''></span><span style='background: #AEF1AE'>        val resArr = ctx.freshName(&quot;resArr&quot;)
</span>132 <span style=''></span><span style='background: #AEF1AE'>
</span>133 <span style=''></span><span style='background: #AEF1AE'>        expr.copy(code =
</span>134 <span style=''></span><span style='background: #AEF1AE'>          code&quot;&quot;&quot;
</span>135 <span style=''></span><span style='background: #AEF1AE'>            org.apache.spark.sql.catalyst.expressions.GenericInternalRow ${expr.value} = null;
</span>136 <span style=''></span><span style='background: #AEF1AE'>            java.util.Map $mapName = (java.util.Map&lt;String, Object&gt;)$pathName;
</span>137 <span style=''></span><span style='background: #AEF1AE'>            boolean ${expr.isNull} = false;
</span>138 <span style=''></span><span style='background: #AEF1AE'>            if ($pathNameIsNull) {
</span>139 <span style=''></span><span style='background: #AEF1AE'>              ${expr.isNull} = true;
</span>140 <span style=''></span><span style='background: #AEF1AE'>            } else {
</span>141 <span style=''></span><span style='background: #AEF1AE'>              $init
</span>142 <span style=''></span><span style='background: #AEF1AE'>              Object[] $resArr = new Object[]{$fields};
</span>143 <span style=''></span><span style='background: #AEF1AE'>
</span>144 <span style=''></span><span style='background: #AEF1AE'>              ${expr.value} = new org.apache.spark.sql.catalyst.expressions.GenericInternalRow(
</span>145 <span style=''></span><span style='background: #AEF1AE'>                $resArr
</span>146 <span style=''></span><span style='background: #AEF1AE'>              );
</span>147 <span style=''></span><span style='background: #AEF1AE'>            }
</span>148 <span style=''></span><span style='background: #AEF1AE'>              &quot;&quot;&quot;
</span>149 <span style=''></span><span style='background: #AEF1AE'>        )
</span>150 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>151 <span style=''>    case StringType =&gt; </span><span style='background: #AEF1AE'>nullOr[String]( path =&gt; s&quot;UTF8String.fromString( $path.toString() )&quot;)</span><span style=''>
</span>152 <span style=''>    case IntegerType =&gt; </span><span style='background: #F0ADAD'>nullOr[Integer]()</span><span style=''>
</span>153 <span style=''>    case LongType =&gt; </span><span style='background: #F0ADAD'>nullOr[Long]()</span><span style=''>
</span>154 <span style=''>    case BooleanType =&gt; </span><span style='background: #AEF1AE'>nullOr[Boolean]()</span><span style=''>
</span>155 <span style=''>    case DoubleType =&gt; </span><span style='background: #F0ADAD'>nullOr[Double]()</span><span style=''>
</span>156 <span style=''>    case FloatType =&gt; </span><span style='background: #F0ADAD'>nullOr[Float]()</span><span style=''>
</span>157 <span style=''>    case BinaryType =&gt; </span><span style='background: #F0ADAD'>nullOr[Array[Byte]]()</span><span style=''>
</span>158 <span style=''>    case ByteType =&gt; </span><span style='background: #F0ADAD'>nullOr[Byte]()</span><span style=''>
</span>159 <span style=''>    case ShortType =&gt; </span><span style='background: #F0ADAD'>nullOr[Short]()</span><span style=''>
</span>160 <span style=''>    case DateType =&gt;
</span>161 <span style=''>      </span><span style='background: #F0ADAD'>nullOr[Int]( path =&gt; s&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateToDays( (java.time.LocalDate) $path )&quot;)</span><span style=''>
</span>162 <span style=''>    case TimestampType =&gt;
</span>163 <span style=''>      </span><span style='background: #F0ADAD'>nullOr[Long]( path =&gt; s&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateTimeToMicros( (java.time.LocalDateTime) $path )&quot;)</span><span style=''>
</span>164 <span style=''>    case _: DecimalType =&gt;
</span>165 <span style=''>      </span><span style='background: #AEF1AE'>nullOr[Decimal]( path =&gt; s&quot;org.apache.spark.sql.types.Decimal.apply( (java.math.BigDecimal) $path )&quot;)</span><span style=''>
</span>166 <span style=''>    case ArrayType(typ, _) =&gt;
</span>167 <span style=''>      </span><span style='background: #AEF1AE'>(ctx: CodegenContext, pathName: String, pathNameIsNull: String) =&gt; {
</span>168 <span style=''></span><span style='background: #AEF1AE'>        val expr = exprCode(classOf[GenericArrayData],ctx)
</span>169 <span style=''></span><span style='background: #AEF1AE'>
</span>170 <span style=''></span><span style='background: #AEF1AE'>        val iar = ctx.freshVariable(&quot;ar&quot;, classOf[util.List[Object]])
</span>171 <span style=''></span><span style='background: #AEF1AE'>
</span>172 <span style=''></span><span style='background: #AEF1AE'>        val i = ctx.freshVariable(&quot;i&quot;, classOf[Int])
</span>173 <span style=''></span><span style='background: #AEF1AE'>
</span>174 <span style=''></span><span style='background: #AEF1AE'>        val arrRes = ctx.freshVariable(&quot;arr&quot;, classOf[Array[Object]])
</span>175 <span style=''></span><span style='background: #AEF1AE'>
</span>176 <span style=''></span><span style='background: #AEF1AE'>        val typCode = forTypeCodeGen(typ).forPath(ctx, s&quot;$arrRes[$i]&quot;, expr.isNull)
</span>177 <span style=''></span><span style='background: #AEF1AE'>
</span>178 <span style=''></span><span style='background: #AEF1AE'>        expr.copy(
</span>179 <span style=''></span><span style='background: #AEF1AE'>          code =
</span>180 <span style=''></span><span style='background: #AEF1AE'>            code&quot;&quot;&quot;
</span>181 <span style=''></span><span style='background: #AEF1AE'>            org.apache.spark.sql.catalyst.util.GenericArrayData ${expr.value} = null;
</span>182 <span style=''></span><span style='background: #AEF1AE'>            java.util.List $iar = (java.util.List&lt;Object&gt;)$pathName;
</span>183 <span style=''></span><span style='background: #AEF1AE'>            boolean ${expr.isNull} = false;
</span>184 <span style=''></span><span style='background: #AEF1AE'>            if ($pathNameIsNull) {
</span>185 <span style=''></span><span style='background: #AEF1AE'>              ${expr.isNull} = true;
</span>186 <span style=''></span><span style='background: #AEF1AE'>            } else {
</span>187 <span style=''></span><span style='background: #AEF1AE'>              Object[] $arrRes = $iar.toArray();
</span>188 <span style=''></span><span style='background: #AEF1AE'>
</span>189 <span style=''></span><span style='background: #AEF1AE'>              for (int $i = 0; $i &lt; $arrRes.length; $i++) {
</span>190 <span style=''></span><span style='background: #AEF1AE'>                ${typCode.code}
</span>191 <span style=''></span><span style='background: #AEF1AE'>                $arrRes[$i] = ${typCode.value};
</span>192 <span style=''></span><span style='background: #AEF1AE'>              }
</span>193 <span style=''></span><span style='background: #AEF1AE'>              ${expr.value} = new org.apache.spark.sql.catalyst.util.GenericArrayData($arrRes);
</span>194 <span style=''></span><span style='background: #AEF1AE'>            }
</span>195 <span style=''></span><span style='background: #AEF1AE'>            &quot;&quot;&quot;
</span>196 <span style=''></span><span style='background: #AEF1AE'>        )
</span>197 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>198 <span style=''>    case MapType(k, v, _) =&gt;
</span>199 <span style=''>      </span><span style='background: #AEF1AE'>(ctx: CodegenContext, pathName: String, pathNameIsNull: String) =&gt; {
</span>200 <span style=''></span><span style='background: #AEF1AE'>        val expr = exprCode(classOf[ArrayBasedMapData], ctx)
</span>201 <span style=''></span><span style='background: #AEF1AE'>
</span>202 <span style=''></span><span style='background: #AEF1AE'>        val map = ctx.freshVariable(&quot;map&quot;, classOf[util.Map[String, Object]])
</span>203 <span style=''></span><span style='background: #AEF1AE'>
</span>204 <span style=''></span><span style='background: #AEF1AE'>        val i = ctx.freshVariable(&quot;i&quot;, classOf[Int])
</span>205 <span style=''></span><span style='background: #AEF1AE'>
</span>206 <span style=''></span><span style='background: #AEF1AE'>        val entry = ctx.freshVariable(&quot;entry&quot;, classOf[util.Map.Entry[String, Object]])
</span>207 <span style=''></span><span style='background: #AEF1AE'>
</span>208 <span style=''></span><span style='background: #AEF1AE'>        val typCodeK = forTypeCodeGen(k).forPath(ctx, s&quot;$entry.getKey()&quot;, expr.isNull)
</span>209 <span style=''></span><span style='background: #AEF1AE'>        val typCodeV = forTypeCodeGen(v).forPath(ctx, s&quot;$entry.getValue()&quot;, expr.isNull)
</span>210 <span style=''></span><span style='background: #AEF1AE'>
</span>211 <span style=''></span><span style='background: #AEF1AE'>        val arrKeyRes = ctx.freshVariable(&quot;arrKey&quot;, classOf[Array[Object]])
</span>212 <span style=''></span><span style='background: #AEF1AE'>        val arrValueRes = ctx.freshVariable(&quot;arrValue&quot;, classOf[Array[Object]])
</span>213 <span style=''></span><span style='background: #AEF1AE'>
</span>214 <span style=''></span><span style='background: #AEF1AE'>        val itr = ctx.freshName(&quot;itr&quot;)
</span>215 <span style=''></span><span style='background: #AEF1AE'>        // NB most maps iterators aren't bounds checking, AbstractCollection.toArray uses iterator anyway
</span>216 <span style=''></span><span style='background: #AEF1AE'>        expr.copy(
</span>217 <span style=''></span><span style='background: #AEF1AE'>          code =
</span>218 <span style=''></span><span style='background: #AEF1AE'>            code&quot;&quot;&quot;
</span>219 <span style=''></span><span style='background: #AEF1AE'>            org.apache.spark.sql.catalyst.util.ArrayBasedMapData ${expr.value} = null;
</span>220 <span style=''></span><span style='background: #AEF1AE'>            java.util.Map $map = (java.util.Map&lt;String, Object&gt;)$pathName;
</span>221 <span style=''></span><span style='background: #AEF1AE'>            boolean ${expr.isNull} = false;
</span>222 <span style=''></span><span style='background: #AEF1AE'>            if ($pathNameIsNull) {
</span>223 <span style=''></span><span style='background: #AEF1AE'>              ${expr.isNull} = true;
</span>224 <span style=''></span><span style='background: #AEF1AE'>            } else {
</span>225 <span style=''></span><span style='background: #AEF1AE'>              Object[] $arrKeyRes = new Object[$map.size()];
</span>226 <span style=''></span><span style='background: #AEF1AE'>              Object[] $arrValueRes = new Object[$map.size()];
</span>227 <span style=''></span><span style='background: #AEF1AE'>              java.util.Iterator&lt;java.util.Map.Entry&lt;String, Object&gt;&gt; $itr = $map.entrySet().iterator();
</span>228 <span style=''></span><span style='background: #AEF1AE'>              int $i = 0;
</span>229 <span style=''></span><span style='background: #AEF1AE'>              while ($itr.hasNext()){
</span>230 <span style=''></span><span style='background: #AEF1AE'>                java.util.Map.Entry&lt;String, Object&gt; $entry = (java.util.Map.Entry&lt;String, Object&gt;) $itr.next();
</span>231 <span style=''></span><span style='background: #AEF1AE'>                ${typCodeK.code}
</span>232 <span style=''></span><span style='background: #AEF1AE'>                ${typCodeV.code}
</span>233 <span style=''></span><span style='background: #AEF1AE'>                $arrKeyRes[$i] = ${typCodeK.value};
</span>234 <span style=''></span><span style='background: #AEF1AE'>                $arrValueRes[$i] = ${typCodeV.value};
</span>235 <span style=''></span><span style='background: #AEF1AE'>                $i = $i + 1;
</span>236 <span style=''></span><span style='background: #AEF1AE'>              }
</span>237 <span style=''></span><span style='background: #AEF1AE'>
</span>238 <span style=''></span><span style='background: #AEF1AE'>              ${expr.value} = new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(
</span>239 <span style=''></span><span style='background: #AEF1AE'>                new org.apache.spark.sql.catalyst.util.GenericArrayData($arrKeyRes),
</span>240 <span style=''></span><span style='background: #AEF1AE'>                new org.apache.spark.sql.catalyst.util.GenericArrayData($arrValueRes)
</span>241 <span style=''></span><span style='background: #AEF1AE'>                );
</span>242 <span style=''></span><span style='background: #AEF1AE'>            }
</span>243 <span style=''></span><span style='background: #AEF1AE'>            &quot;&quot;&quot;
</span>244 <span style=''></span><span style='background: #AEF1AE'>        )
</span>245 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>246 <span style=''>    case _ =&gt; </span><span style='background: #F0ADAD'>throw new DMNException(s&quot;Could not load Kogito Result Provider for dataType $dataType&quot;)</span><span style=''>
</span>247 <span style=''>  }
</span>248 <span style=''>
</span>249 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          23
        </td>
        <td>
          892
        </td>
        <td>
          1047
          -
          1063
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;_dmnEvalStatus&quot;
        </td>
      </tr><tr>
        <td>
          26
        </td>
        <td>
          893
        </td>
        <td>
          1130
          -
          1132
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -6
        </td>
      </tr><tr>
        <td>
          26
        </td>
        <td>
          894
        </td>
        <td>
          1130
          -
          1139
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toByte
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -6.toByte
        </td>
      </tr><tr>
        <td>
          27
        </td>
        <td>
          895
        </td>
        <td>
          1278
          -
          1280
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -5
        </td>
      </tr><tr>
        <td>
          27
        </td>
        <td>
          896
        </td>
        <td>
          1278
          -
          1287
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toByte
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -5.toByte
        </td>
      </tr><tr>
        <td>
          28
        </td>
        <td>
          897
        </td>
        <td>
          1333
          -
          1335
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -4
        </td>
      </tr><tr>
        <td>
          28
        </td>
        <td>
          898
        </td>
        <td>
          1333
          -
          1342
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toByte
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -4.toByte
        </td>
      </tr><tr>
        <td>
          29
        </td>
        <td>
          899
        </td>
        <td>
          1431
          -
          1432
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1
        </td>
      </tr><tr>
        <td>
          29
        </td>
        <td>
          900
        </td>
        <td>
          1431
          -
          1439
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toByte
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1.toByte
        </td>
      </tr><tr>
        <td>
          30
        </td>
        <td>
          901
        </td>
        <td>
          1468
          -
          1470
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -3
        </td>
      </tr><tr>
        <td>
          30
        </td>
        <td>
          902
        </td>
        <td>
          1468
          -
          1477
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toByte
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -3.toByte
        </td>
      </tr><tr>
        <td>
          31
        </td>
        <td>
          903
        </td>
        <td>
          1507
          -
          1509
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -2
        </td>
      </tr><tr>
        <td>
          31
        </td>
        <td>
          904
        </td>
        <td>
          1507
          -
          1516
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toByte
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          -2.toByte
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          905
        </td>
        <td>
          1539
          -
          1540
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          906
        </td>
        <td>
          1539
          -
          1547
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toByte
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0.toByte
        </td>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          930
        </td>
        <td>
          1692
          -
          2133
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val s: Array[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)] = scala.Predef.refArrayOps[org.apache.spark.sql.types.StructField](structType.fields).map[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter), Array[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)]](((f: org.apache.spark.sql.types.StructField) =&gt; scala.Tuple2.apply[String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter](f.name, if (f.name.endsWith(ResultInterfaces.this.evalStatusEnding))
    (((path: Any) =&gt; ResultInterfaces.this.EVALUATING): com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)
  else
    ResultInterfaces.this.forType(f.dataType))))(scala.this.Array.canBuildFrom[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)]((ClassTag.apply[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)])));
  ((path: Any) =&gt; if (path.==(null))
    null
  else
    {
      val m: java.util.Map[String,Object] = path.asInstanceOf[java.util.Map[String,Object]];
      org.apache.spark.sql.catalyst.InternalRow.apply((scala.Predef.refArrayOps[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)](s).map[Any, Array[Any]](((x0$1: (String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)) =&gt; x0$1 match {
        case (_1: String, _2: com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)((name @ _), (g @ _)) =&gt; g.get(m.get(name))
      }))(scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))): _*))
    })
}
        </td>
      </tr><tr>
        <td>
          41
        </td>
        <td>
          907
        </td>
        <td>
          1710
          -
          1727
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructType.fields
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          structType.fields
        </td>
      </tr><tr>
        <td>
          41
        </td>
        <td>
          917
        </td>
        <td>
          1732
          -
          1732
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)]((ClassTag.apply[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)]))
        </td>
      </tr><tr>
        <td>
          41
        </td>
        <td>
          918
        </td>
        <td>
          1710
          -
          1917
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[org.apache.spark.sql.types.StructField](structType.fields).map[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter), Array[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)]](((f: org.apache.spark.sql.types.StructField) =&gt; scala.Tuple2.apply[String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter](f.name, if (f.name.endsWith(ResultInterfaces.this.evalStatusEnding))
  (((path: Any) =&gt; ResultInterfaces.this.EVALUATING): com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)
else
  ResultInterfaces.this.forType(f.dataType))))(scala.this.Array.canBuildFrom[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)]((ClassTag.apply[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)])))
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          908
        </td>
        <td>
          1748
          -
          1754
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.name
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          916
        </td>
        <td>
          1747
          -
          1909
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter](f.name, if (f.name.endsWith(ResultInterfaces.this.evalStatusEnding))
  (((path: Any) =&gt; ResultInterfaces.this.EVALUATING): com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)
else
  ResultInterfaces.this.forType(f.dataType))
        </td>
      </tr><tr>
        <td>
          43
        </td>
        <td>
          909
        </td>
        <td>
          1786
          -
          1802
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.evalStatusEnding
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.evalStatusEnding
        </td>
      </tr><tr>
        <td>
          43
        </td>
        <td>
          910
        </td>
        <td>
          1770
          -
          1803
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.endsWith
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.name.endsWith(ResultInterfaces.this.evalStatusEnding)
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          911
        </td>
        <td>
          1833
          -
          1843
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.EVALUATING
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          912
        </td>
        <td>
          1818
          -
          1852
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          (((path: Any) =&gt; ResultInterfaces.this.EVALUATING): com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          913
        </td>
        <td>
          1888
          -
          1898
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.dataType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.dataType
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          914
        </td>
        <td>
          1880
          -
          1899
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.forType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forType(f.dataType)
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          915
        </td>
        <td>
          1880
          -
          1899
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.forType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forType(f.dataType)
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          919
        </td>
        <td>
          1954
          -
          1966
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          920
        </td>
        <td>
          1968
          -
          1972
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          921
        </td>
        <td>
          1968
          -
          1972
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          929
        </td>
        <td>
          1978
          -
          2125
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val m: java.util.Map[String,Object] = path.asInstanceOf[java.util.Map[String,Object]];
  org.apache.spark.sql.catalyst.InternalRow.apply((scala.Predef.refArrayOps[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)](s).map[Any, Array[Any]](((x0$1: (String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)) =&gt; x0$1 match {
    case (_1: String, _2: com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)((name @ _), (g @ _)) =&gt; g.get(m.get(name))
  }))(scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))): _*))
}
        </td>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          922
        </td>
        <td>
          1998
          -
          2041
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.asInstanceOf[java.util.Map[String,Object]]
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          923
        </td>
        <td>
          2096
          -
          2107
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.get(name)
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          924
        </td>
        <td>
          2090
          -
          2108
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          g.get(m.get(name))
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          925
        </td>
        <td>
          2090
          -
          2108
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          g.get(m.get(name))
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          926
        </td>
        <td>
          2070
          -
          2070
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          927
        </td>
        <td>
          2064
          -
          2110
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)](s).map[Any, Array[Any]](((x0$1: (String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)) =&gt; x0$1 match {
  case (_1: String, _2: com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)((name @ _), (g @ _)) =&gt; g.get(m.get(name))
}))(scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any])))
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          928
        </td>
        <td>
          2052
          -
          2115
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.InternalRow.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.InternalRow.apply((scala.Predef.refArrayOps[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)](s).map[Any, Array[Any]](((x0$1: (String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)) =&gt; x0$1 match {
  case (_1: String, _2: com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter)((name @ _), (g @ _)) =&gt; g.get(m.get(name))
}))(scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))): _*))
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          931
        </td>
        <td>
          2176
          -
          2188
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          932
        </td>
        <td>
          2190
          -
          2194
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          933
        </td>
        <td>
          2190
          -
          2194
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          934
        </td>
        <td>
          2223
          -
          2236
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.toString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.toString()
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          935
        </td>
        <td>
          2200
          -
          2238
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.unsafe.types.UTF8String.fromString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.unsafe.types.UTF8String.fromString(path.toString())
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          936
        </td>
        <td>
          2200
          -
          2238
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.unsafe.types.UTF8String.fromString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.unsafe.types.UTF8String.fromString(path.toString())
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          937
        </td>
        <td>
          2157
          -
          2238
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  org.apache.spark.unsafe.types.UTF8String.fromString(path.toString()))
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          938
        </td>
        <td>
          2282
          -
          2294
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          939
        </td>
        <td>
          2296
          -
          2300
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          940
        </td>
        <td>
          2296
          -
          2300
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          941
        </td>
        <td>
          2306
          -
          2332
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Integer]
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          942
        </td>
        <td>
          2306
          -
          2332
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Integer]
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          943
        </td>
        <td>
          2263
          -
          2332
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Integer])
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          944
        </td>
        <td>
          2373
          -
          2385
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          945
        </td>
        <td>
          2387
          -
          2391
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          946
        </td>
        <td>
          2387
          -
          2391
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          947
        </td>
        <td>
          2397
          -
          2420
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Long]
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          948
        </td>
        <td>
          2397
          -
          2420
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Long]
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          949
        </td>
        <td>
          2354
          -
          2420
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Long])
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          950
        </td>
        <td>
          2464
          -
          2476
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          951
        </td>
        <td>
          2478
          -
          2482
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          952
        </td>
        <td>
          2478
          -
          2482
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          953
        </td>
        <td>
          2488
          -
          2514
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.asInstanceOf[Boolean]
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          954
        </td>
        <td>
          2488
          -
          2514
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.asInstanceOf[Boolean]
        </td>
      </tr><tr>
        <td>
          59
        </td>
        <td>
          955
        </td>
        <td>
          2445
          -
          2514
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Boolean])
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          956
        </td>
        <td>
          2557
          -
          2569
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          957
        </td>
        <td>
          2571
          -
          2575
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          958
        </td>
        <td>
          2571
          -
          2575
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          959
        </td>
        <td>
          2581
          -
          2606
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Double]
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          960
        </td>
        <td>
          2581
          -
          2606
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Double]
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          961
        </td>
        <td>
          2538
          -
          2606
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Double])
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          962
        </td>
        <td>
          2648
          -
          2660
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          963
        </td>
        <td>
          2662
          -
          2666
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          964
        </td>
        <td>
          2662
          -
          2666
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          965
        </td>
        <td>
          2672
          -
          2696
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Float]
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          966
        </td>
        <td>
          2672
          -
          2696
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Float]
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          967
        </td>
        <td>
          2629
          -
          2696
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Float])
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          968
        </td>
        <td>
          2739
          -
          2751
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          969
        </td>
        <td>
          2753
          -
          2757
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          970
        </td>
        <td>
          2753
          -
          2757
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          971
        </td>
        <td>
          2763
          -
          2793
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Array[Byte]]
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          972
        </td>
        <td>
          2763
          -
          2793
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Array[Byte]]
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          973
        </td>
        <td>
          2720
          -
          2793
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Array[Byte]])
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          974
        </td>
        <td>
          2834
          -
          2846
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          975
        </td>
        <td>
          2848
          -
          2852
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          976
        </td>
        <td>
          2848
          -
          2852
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          977
        </td>
        <td>
          2858
          -
          2881
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          978
        </td>
        <td>
          2858
          -
          2881
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          979
        </td>
        <td>
          2815
          -
          2881
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          980
        </td>
        <td>
          2923
          -
          2935
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          981
        </td>
        <td>
          2937
          -
          2941
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          982
        </td>
        <td>
          2937
          -
          2941
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          983
        </td>
        <td>
          2947
          -
          2971
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Short]
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          984
        </td>
        <td>
          2947
          -
          2971
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[Short]
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          985
        </td>
        <td>
          2904
          -
          2971
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  path.asInstanceOf[Short])
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          986
        </td>
        <td>
          3012
          -
          3024
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          987
        </td>
        <td>
          3026
          -
          3030
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          988
        </td>
        <td>
          3026
          -
          3030
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          989
        </td>
        <td>
          3067
          -
          3095
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[java.time.LocalDate]
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          990
        </td>
        <td>
          3036
          -
          3097
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.SparkDateTimeUtils.localDateToDays
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateToDays(path.asInstanceOf[java.time.LocalDate])
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          991
        </td>
        <td>
          3036
          -
          3097
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.SparkDateTimeUtils.localDateToDays
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateToDays(path.asInstanceOf[java.time.LocalDate])
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          992
        </td>
        <td>
          2993
          -
          3097
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateToDays(path.asInstanceOf[java.time.LocalDate]))
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          993
        </td>
        <td>
          3143
          -
          3155
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          994
        </td>
        <td>
          3157
          -
          3161
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          995
        </td>
        <td>
          3157
          -
          3161
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          996
        </td>
        <td>
          3204
          -
          3236
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          path.asInstanceOf[java.time.LocalDateTime]
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          997
        </td>
        <td>
          3167
          -
          3238
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.SparkDateTimeUtils.localDateTimeToMicros
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateTimeToMicros(path.asInstanceOf[java.time.LocalDateTime])
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          998
        </td>
        <td>
          3167
          -
          3238
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.SparkDateTimeUtils.localDateTimeToMicros
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateTimeToMicros(path.asInstanceOf[java.time.LocalDateTime])
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          999
        </td>
        <td>
          3124
          -
          3238
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateTimeToMicros(path.asInstanceOf[java.time.LocalDateTime]))
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          1006
        </td>
        <td>
          3266
          -
          3369
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((path: Any) =&gt; if (path.==(null))
  null
else
  org.apache.spark.sql.types.Decimal.apply(path.asInstanceOf[java.math.BigDecimal]))
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          1000
        </td>
        <td>
          3291
          -
          3303
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          1001
        </td>
        <td>
          3305
          -
          3309
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          1002
        </td>
        <td>
          3305
          -
          3309
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          1003
        </td>
        <td>
          3329
          -
          3368
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.asInstanceOf[java.math.BigDecimal]
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          1004
        </td>
        <td>
          3315
          -
          3369
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.types.Decimal.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.Decimal.apply(path.asInstanceOf[java.math.BigDecimal])
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          1005
        </td>
        <td>
          3315
          -
          3369
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.sql.types.Decimal.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.Decimal.apply(path.asInstanceOf[java.math.BigDecimal])
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          1017
        </td>
        <td>
          3397
          -
          3611
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val g: com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter = ResultInterfaces.this.forType(typ);
  ((path: Any) =&gt; if (path.==(null))
    null
  else
    {
      val a: Array[Any] = scala.Predef.refArrayOps[Object](path.asInstanceOf[java.util.List[_]].toArray()).map[Any, Array[Any]](((x$1: Object) =&gt; g.get(x$1)))(scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any])));
      new org.apache.spark.sql.catalyst.util.GenericArrayData(a)
    })
}
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          1007
        </td>
        <td>
          3414
          -
          3426
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.forType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forType(typ)
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          1008
        </td>
        <td>
          3462
          -
          3474
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          1009
        </td>
        <td>
          3476
          -
          3480
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          1010
        </td>
        <td>
          3476
          -
          3480
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          1016
        </td>
        <td>
          3486
          -
          3603
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val a: Array[Any] = scala.Predef.refArrayOps[Object](path.asInstanceOf[java.util.List[_]].toArray()).map[Any, Array[Any]](((x$1: Object) =&gt; g.get(x$1)))(scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any])));
  new org.apache.spark.sql.catalyst.util.GenericArrayData(a)
}
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          1011
        </td>
        <td>
          3506
          -
          3545
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.List.toArray
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.asInstanceOf[java.util.List[_]].toArray()
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          1012
        </td>
        <td>
          3550
          -
          3558
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          g.get(x$1)
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          1013
        </td>
        <td>
          3549
          -
          3549
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          1014
        </td>
        <td>
          3506
          -
          3559
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[Object](path.asInstanceOf[java.util.List[_]].toArray()).map[Any, Array[Any]](((x$1: Object) =&gt; g.get(x$1)))(scala.this.Array.canBuildFrom[Any]((ClassTag.Any: scala.reflect.ClassTag[Any])))
        </td>
      </tr><tr>
        <td>
          74
        </td>
        <td>
          1015
        </td>
        <td>
          3570
          -
          3593
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.GenericArrayData.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.sql.catalyst.util.GenericArrayData(a)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          1038
        </td>
        <td>
          3638
          -
          3996
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val kG: com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter = ResultInterfaces.this.forType(k);
  val vG: com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter = ResultInterfaces.this.forType(v);
  ((path: Any) =&gt; if (path.==(null))
    null
  else
    {
      val m: scala.collection.immutable.Map[Any,Any] = scala.collection.JavaConverters.mapAsScalaMapConverter[Object, Object](path.asInstanceOf[java.util.Map[Object,Object]]).asScala.toMap[Object, Object](scala.Predef.$conforms[(Object, Object)]).map[(Any, Any), scala.collection.immutable.Map[Any,Any]](((e: (Object, Object)) =&gt; scala.Predef.ArrowAssoc[Any](kG.get(e._1)).-&gt;[Any](vG.get(e._2))))(immutable.this.Map.canBuildFrom[Any, Any]);
      new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(new org.apache.spark.sql.catalyst.util.GenericArrayData(m.keys.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))), new org.apache.spark.sql.catalyst.util.GenericArrayData(m.values.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))))
    })
}
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          1018
        </td>
        <td>
          3656
          -
          3666
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.forType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forType(k)
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          1019
        </td>
        <td>
          3682
          -
          3692
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.forType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forType(v)
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          1020
        </td>
        <td>
          3728
          -
          3740
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.==(null)
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          1021
        </td>
        <td>
          3742
          -
          3746
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          1022
        </td>
        <td>
          3742
          -
          3746
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          1037
        </td>
        <td>
          3752
          -
          3988
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val m: scala.collection.immutable.Map[Any,Any] = scala.collection.JavaConverters.mapAsScalaMapConverter[Object, Object](path.asInstanceOf[java.util.Map[Object,Object]]).asScala.toMap[Object, Object](scala.Predef.$conforms[(Object, Object)]).map[(Any, Any), scala.collection.immutable.Map[Any,Any]](((e: (Object, Object)) =&gt; scala.Predef.ArrowAssoc[Any](kG.get(e._1)).-&gt;[Any](vG.get(e._2))))(immutable.this.Map.canBuildFrom[Any, Any]);
  new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(new org.apache.spark.sql.catalyst.util.GenericArrayData(m.keys.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))), new org.apache.spark.sql.catalyst.util.GenericArrayData(m.values.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))))
}
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1023
        </td>
        <td>
          3772
          -
          3815
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          path.asInstanceOf[java.util.Map[Object,Object]]
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1024
        </td>
        <td>
          3824
          -
          3824
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(Object, Object)]
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1025
        </td>
        <td>
          3846
          -
          3850
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e._1
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1026
        </td>
        <td>
          3839
          -
          3851
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          kG.get(e._1)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1027
        </td>
        <td>
          3862
          -
          3866
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e._2
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1028
        </td>
        <td>
          3855
          -
          3867
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.Getter.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          vG.get(e._2)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1029
        </td>
        <td>
          3839
          -
          3867
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[Any](kG.get(e._1)).-&gt;[Any](vG.get(e._2))
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1030
        </td>
        <td>
          3833
          -
          3833
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Map.canBuildFrom[Any, Any]
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          1031
        </td>
        <td>
          3772
          -
          3868
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.JavaConverters.mapAsScalaMapConverter[Object, Object](path.asInstanceOf[java.util.Map[Object,Object]]).asScala.toMap[Object, Object](scala.Predef.$conforms[(Object, Object)]).map[(Any, Any), scala.collection.immutable.Map[Any,Any]](((e: (Object, Object)) =&gt; scala.Predef.ArrowAssoc[Any](kG.get(e._1)).-&gt;[Any](vG.get(e._2))))(immutable.this.Map.canBuildFrom[Any, Any])
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          1032
        </td>
        <td>
          3922
          -
          3936
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toArray
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.keys.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          1033
        </td>
        <td>
          3901
          -
          3937
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.GenericArrayData.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.sql.catalyst.util.GenericArrayData(m.keys.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any])))
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          1034
        </td>
        <td>
          3960
          -
          3976
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toArray
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          m.values.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          1035
        </td>
        <td>
          3939
          -
          3977
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.GenericArrayData.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.sql.catalyst.util.GenericArrayData(m.values.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any])))
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          1036
        </td>
        <td>
          3879
          -
          3978
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.util.ArrayBasedMapData.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(new org.apache.spark.sql.catalyst.util.GenericArrayData(m.keys.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))), new org.apache.spark.sql.catalyst.util.GenericArrayData(m.values.toArray[Any]((ClassTag.Any: scala.reflect.ClassTag[Any]))))
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          1039
        </td>
        <td>
          4011
          -
          4098
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new com.sparkutils.dmn.DMNException(scala.StringContext.apply(&quot;Could not load Kogito Result Provider for dataType &quot;, &quot;&quot;).s(dataType))
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          1040
        </td>
        <td>
          4011
          -
          4098
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new com.sparkutils.dmn.DMNException(scala.StringContext.apply(&quot;Could not load Kogito Result Provider for dataType &quot;, &quot;&quot;).s(dataType))
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          1041
        </td>
        <td>
          4717
          -
          4728
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function1.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.apply(pathName)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          1042
        </td>
        <td>
          4744
          -
          4768
        </td>
        <td>
          Select
        </td>
        <td>
          scala.reflect.ClassTag.runtimeClass
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.reflect.`package`.classTag[T](evidence$1).runtimeClass
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          1045
        </td>
        <td>
          4735
          -
          4840
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.Arrays.exprCode
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.dmn.kogito.types.Arrays.exprCode(scala.reflect.`package`.classTag[T](evidence$1).runtimeClass, ctx, org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;((&quot;, &quot;) ? null : &quot;, &quot;);&quot;)).code(pathNameIsNull, c), false)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          1043
        </td>
        <td>
          4783
          -
          4825
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;((&quot;, &quot;) ? null : &quot;, &quot;);&quot;)).code(pathNameIsNull, c)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          1044
        </td>
        <td>
          4834
          -
          4839
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          false
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          1083
        </td>
        <td>
          4988
          -
          6458
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((ctx: org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext, pathName: String, pathNameIsNull: String) =&gt; {
  val expr: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode = com.sparkutils.dmn.kogito.types.Arrays.exprCode(classOf[org.apache.spark.sql.catalyst.expressions.GenericInternalRow], ctx);
  val mapName: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;map&quot;, classOf[java.util.Map]);
  val s: Array[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode] = scala.Predef.refArrayOps[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)](scala.Predef.refArrayOps[org.apache.spark.sql.types.StructField](structType.fields).map[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen), Array[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]](((f: org.apache.spark.sql.types.StructField) =&gt; scala.Tuple2.apply[String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen](f.name, if (f.name.endsWith(ResultInterfaces.this.evalStatusEnding))
  ResultInterfaces.this.nullOr[Byte](((x$2: String) =&gt; scala.StringContext.apply(&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;).s()))((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
else
  ResultInterfaces.this.forTypeCodeGen(f.dataType))))(scala.this.Array.canBuildFrom[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]((ClassTag.apply[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)])))).map[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode, Array[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]](((x0$1: (String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)) =&gt; x0$1 match {
    case (_1: String, _2: com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)((n @ _), (f @ _)) =&gt; f.forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.get(\&quot;&quot;, &quot;\&quot;)&quot;).s(mapName, n), codegen.this.ExprValue.exprValueToString(expr.isNull))
  }))(scala.this.Array.canBuildFrom[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]((ClassTag.apply[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](classOf[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]): scala.reflect.ClassTag[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode])));
  val init: org.apache.spark.sql.catalyst.expressions.codegen.Block = scala.Predef.refArrayOps[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](s).foldLeft[org.apache.spark.sql.catalyst.expressions.codegen.Block](org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;&quot;)).code())(((x0$2: org.apache.spark.sql.catalyst.expressions.codegen.Block, x1$1: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode) =&gt; scala.Tuple2.apply[org.apache.spark.sql.catalyst.expressions.codegen.Block, org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](x0$2, x1$1) match {
    case (_1: org.apache.spark.sql.catalyst.expressions.codegen.Block, _2: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)(org.apache.spark.sql.catalyst.expressions.codegen.Block, org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)((c @ _), (e @ _)) =&gt; org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;&quot;, &quot;\n                &quot;, &quot;\n                &quot;)).code(c, e.code)
  }));
  val fields: String = scala.Predef.refArrayOps[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue](scala.Predef.refArrayOps[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](s).map[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue, Array[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue]](((x$3: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode) =&gt; x$3.value))(scala.this.Array.canBuildFrom[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue]((ClassTag.apply[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue](classOf[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue]): scala.reflect.ClassTag[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue])))).mkString(&quot;\n,&quot;);
  val resArr: String = ctx.freshName(&quot;resArr&quot;);
  expr.copy(org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.expressions.GenericInternalRow &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              &quot;, &quot;\n              Object[] &quot;, &quot; = new Object[]{&quot;, &quot;};\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.expressions.GenericInternalRow(\n                &quot;, &quot;\n              );\n            }\n              &quot;)).code(expr.value, mapName, pathName, expr.isNull, pathNameIsNull, expr.isNull, init, resArr, fields, expr.value, resArr), expr.copy$default$2, expr.copy$default$3)
})
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          1046
        </td>
        <td>
          5076
          -
          5117
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.Arrays.exprCode
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.dmn.kogito.types.Arrays.exprCode(classOf[org.apache.spark.sql.catalyst.expressions.GenericInternalRow], ctx)
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          1047
        </td>
        <td>
          5141
          -
          5199
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;map&quot;, classOf[java.util.Map])
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          1048
        </td>
        <td>
          5217
          -
          5234
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructType.fields
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          structType.fields
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          1059
        </td>
        <td>
          5239
          -
          5239
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]((ClassTag.apply[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]))
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          1060
        </td>
        <td>
          5217
          -
          5493
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[org.apache.spark.sql.types.StructField](structType.fields).map[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen), Array[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]](((f: org.apache.spark.sql.types.StructField) =&gt; scala.Tuple2.apply[String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen](f.name, if (f.name.endsWith(ResultInterfaces.this.evalStatusEnding))
  ResultInterfaces.this.nullOr[Byte](((x$2: String) =&gt; scala.StringContext.apply(&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;).s()))((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
else
  ResultInterfaces.this.forTypeCodeGen(f.dataType))))(scala.this.Array.canBuildFrom[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]((ClassTag.apply[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)])))
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          1049
        </td>
        <td>
          5257
          -
          5263
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.name
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.name
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          1058
        </td>
        <td>
          5256
          -
          5483
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen](f.name, if (f.name.endsWith(ResultInterfaces.this.evalStatusEnding))
  ResultInterfaces.this.nullOr[Byte](((x$2: String) =&gt; scala.StringContext.apply(&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;).s()))((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
else
  ResultInterfaces.this.forTypeCodeGen(f.dataType))
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          1050
        </td>
        <td>
          5297
          -
          5313
        </td>
        <td>
          Select
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.evalStatusEnding
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.evalStatusEnding
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          1051
        </td>
        <td>
          5281
          -
          5314
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.endsWith
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.name.endsWith(ResultInterfaces.this.evalStatusEnding)
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          1052
        </td>
        <td>
          5348
          -
          5412
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;).s()
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          1053
        </td>
        <td>
          5330
          -
          5413
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[Byte](((x$2: String) =&gt; scala.StringContext.apply(&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;).s()))((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          1054
        </td>
        <td>
          5330
          -
          5413
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[Byte](((x$2: String) =&gt; scala.StringContext.apply(&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;).s()))((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          1055
        </td>
        <td>
          5460
          -
          5470
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.StructField.dataType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.dataType
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          1056
        </td>
        <td>
          5445
          -
          5471
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.forTypeCodeGen
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forTypeCodeGen(f.dataType)
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          1057
        </td>
        <td>
          5445
          -
          5471
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.forTypeCodeGen
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forTypeCodeGen(f.dataType)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          1066
        </td>
        <td>
          5497
          -
          5497
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]((ClassTag.apply[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](classOf[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]): scala.reflect.ClassTag[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]))
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          1067
        </td>
        <td>
          5217
          -
          5599
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)](scala.Predef.refArrayOps[org.apache.spark.sql.types.StructField](structType.fields).map[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen), Array[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]](((f: org.apache.spark.sql.types.StructField) =&gt; scala.Tuple2.apply[String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen](f.name, if (f.name.endsWith(ResultInterfaces.this.evalStatusEnding))
  ResultInterfaces.this.nullOr[Byte](((x$2: String) =&gt; scala.StringContext.apply(&quot;com.sparkutils.dmn.kogito.types.ResultInterfaces.EVALUATING()&quot;).s()))((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
else
  ResultInterfaces.this.forTypeCodeGen(f.dataType))))(scala.this.Array.canBuildFrom[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)]((ClassTag.apply[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)])))).map[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode, Array[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]](((x0$1: (String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)) =&gt; x0$1 match {
  case (_1: String, _2: com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)(String, com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen)((n @ _), (f @ _)) =&gt; f.forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.get(\&quot;&quot;, &quot;\&quot;)&quot;).s(mapName, n), codegen.this.ExprValue.exprValueToString(expr.isNull))
}))(scala.this.Array.canBuildFrom[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]((ClassTag.apply[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](classOf[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode]): scala.reflect.ClassTag[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode])))
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          1061
        </td>
        <td>
          5550
          -
          5575
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;.get(\&quot;&quot;, &quot;\&quot;)&quot;).s(mapName, n)
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          1062
        </td>
        <td>
          5577
          -
          5588
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          1063
        </td>
        <td>
          5577
          -
          5588
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprValue.exprValueToString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          codegen.this.ExprValue.exprValueToString(expr.isNull)
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          1064
        </td>
        <td>
          5535
          -
          5589
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen.forPath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.get(\&quot;&quot;, &quot;\&quot;)&quot;).s(mapName, n), codegen.this.ExprValue.exprValueToString(expr.isNull))
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          1065
        </td>
        <td>
          5535
          -
          5589
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen.forPath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          f.forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.get(\&quot;&quot;, &quot;\&quot;)&quot;).s(mapName, n), codegen.this.ExprValue.exprValueToString(expr.isNull))
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          1068
        </td>
        <td>
          5630
          -
          5636
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;&quot;)).code()
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          1073
        </td>
        <td>
          5619
          -
          5741
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IndexedSeqOptimized.foldLeft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](s).foldLeft[org.apache.spark.sql.catalyst.expressions.codegen.Block](org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;&quot;)).code())(((x0$2: org.apache.spark.sql.catalyst.expressions.codegen.Block, x1$1: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode) =&gt; scala.Tuple2.apply[org.apache.spark.sql.catalyst.expressions.codegen.Block, org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](x0$2, x1$1) match {
  case (_1: org.apache.spark.sql.catalyst.expressions.codegen.Block, _2: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)(org.apache.spark.sql.catalyst.expressions.codegen.Block, org.apache.spark.sql.catalyst.expressions.codegen.ExprCode)((c @ _), (e @ _)) =&gt; org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;&quot;, &quot;\n                &quot;, &quot;\n                &quot;)).code(c, e.code)
}))
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          1069
        </td>
        <td>
          5676
          -
          5731
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;\n                &quot;, &quot;\n                &quot;)
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          1071
        </td>
        <td>
          5676
          -
          5731
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;&quot;, &quot;\n                &quot;, &quot;\n                &quot;)).code(c, e.code)
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          1072
        </td>
        <td>
          5676
          -
          5731
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;&quot;, &quot;\n                &quot;, &quot;\n                &quot;)).code(c, e.code)
        </td>
      </tr><tr>
        <td>
          126
        </td>
        <td>
          1070
        </td>
        <td>
          5704
          -
          5710
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          e.code
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          1074
        </td>
        <td>
          5763
          -
          5793
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.mkString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue](scala.Predef.refArrayOps[org.apache.spark.sql.catalyst.expressions.codegen.ExprCode](s).map[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue, Array[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue]](((x$3: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode) =&gt; x$3.value))(scala.this.Array.canBuildFrom[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue]((ClassTag.apply[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue](classOf[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue]): scala.reflect.ClassTag[org.apache.spark.sql.catalyst.expressions.codegen.ExprValue])))).mkString(&quot;\n,&quot;)
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          1075
        </td>
        <td>
          5816
          -
          5839
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshName(&quot;resArr&quot;)
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          1082
        </td>
        <td>
          5849
          -
          6450
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.copy(org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.expressions.GenericInternalRow &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              &quot;, &quot;\n              Object[] &quot;, &quot; = new Object[]{&quot;, &quot;};\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.expressions.GenericInternalRow(\n                &quot;, &quot;\n              );\n            }\n              &quot;)).code(expr.value, mapName, pathName, expr.isNull, pathNameIsNull, expr.isNull, init, resArr, fields, expr.value, resArr), expr.copy$default$2, expr.copy$default$3)
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          1076
        </td>
        <td>
          5876
          -
          6440
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.expressions.GenericInternalRow &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              &quot;, &quot;\n              Object[] &quot;, &quot; = new Object[]{&quot;, &quot;};\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.expressions.GenericInternalRow(\n                &quot;, &quot;\n              );\n            }\n              &quot;)
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          1081
        </td>
        <td>
          5876
          -
          6440
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.expressions.GenericInternalRow &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              &quot;, &quot;\n              Object[] &quot;, &quot; = new Object[]{&quot;, &quot;};\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.expressions.GenericInternalRow(\n                &quot;, &quot;\n              );\n            }\n              &quot;)).code(expr.value, mapName, pathName, expr.isNull, pathNameIsNull, expr.isNull, init, resArr, fields, expr.value, resArr)
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          1077
        </td>
        <td>
          5959
          -
          5969
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.value
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          1078
        </td>
        <td>
          6080
          -
          6091
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          1079
        </td>
        <td>
          6153
          -
          6164
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          1080
        </td>
        <td>
          6288
          -
          6298
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.value
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          1084
        </td>
        <td>
          6506
          -
          6550
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;UTF8String.fromString( &quot;, &quot;.toString() )&quot;).s(path)
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          1085
        </td>
        <td>
          6482
          -
          6551
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[String](((path: String) =&gt; scala.StringContext.apply(&quot;UTF8String.fromString( &quot;, &quot;.toString() )&quot;).s(path)))((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          1086
        </td>
        <td>
          6482
          -
          6551
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[String](((path: String) =&gt; scala.StringContext.apply(&quot;UTF8String.fromString( &quot;, &quot;.toString() )&quot;).s(path)))((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          152
        </td>
        <td>
          1087
        </td>
        <td>
          6582
          -
          6582
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr$default$1[Integer]
        </td>
      </tr><tr>
        <td>
          152
        </td>
        <td>
          1088
        </td>
        <td>
          6576
          -
          6593
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Integer](ResultInterfaces.this.nullOr$default$1[Integer])((ClassTag.apply[Integer](classOf[java.lang.Integer]): scala.reflect.ClassTag[Integer]))
        </td>
      </tr><tr>
        <td>
          152
        </td>
        <td>
          1089
        </td>
        <td>
          6576
          -
          6593
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Integer](ResultInterfaces.this.nullOr$default$1[Integer])((ClassTag.apply[Integer](classOf[java.lang.Integer]): scala.reflect.ClassTag[Integer]))
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          1090
        </td>
        <td>
          6621
          -
          6621
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr$default$1[Long]
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          1091
        </td>
        <td>
          6615
          -
          6629
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Long](ResultInterfaces.this.nullOr$default$1[Long])((ClassTag.Long: scala.reflect.ClassTag[Long]))
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          1092
        </td>
        <td>
          6615
          -
          6629
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Long](ResultInterfaces.this.nullOr$default$1[Long])((ClassTag.Long: scala.reflect.ClassTag[Long]))
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          1093
        </td>
        <td>
          6660
          -
          6660
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr$default$1[Boolean]
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          1094
        </td>
        <td>
          6654
          -
          6671
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[Boolean](ResultInterfaces.this.nullOr$default$1[Boolean])((ClassTag.Boolean: scala.reflect.ClassTag[Boolean]))
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          1095
        </td>
        <td>
          6654
          -
          6671
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[Boolean](ResultInterfaces.this.nullOr$default$1[Boolean])((ClassTag.Boolean: scala.reflect.ClassTag[Boolean]))
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          1096
        </td>
        <td>
          6701
          -
          6701
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr$default$1[Double]
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          1097
        </td>
        <td>
          6695
          -
          6711
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Double](ResultInterfaces.this.nullOr$default$1[Double])((ClassTag.Double: scala.reflect.ClassTag[Double]))
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          1098
        </td>
        <td>
          6695
          -
          6711
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Double](ResultInterfaces.this.nullOr$default$1[Double])((ClassTag.Double: scala.reflect.ClassTag[Double]))
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          1099
        </td>
        <td>
          6740
          -
          6740
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr$default$1[Float]
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          1100
        </td>
        <td>
          6734
          -
          6749
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Float](ResultInterfaces.this.nullOr$default$1[Float])((ClassTag.Float: scala.reflect.ClassTag[Float]))
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          1101
        </td>
        <td>
          6734
          -
          6749
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Float](ResultInterfaces.this.nullOr$default$1[Float])((ClassTag.Float: scala.reflect.ClassTag[Float]))
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          1102
        </td>
        <td>
          6779
          -
          6779
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr$default$1[Array[Byte]]
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          1103
        </td>
        <td>
          6773
          -
          6794
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Array[Byte]](ResultInterfaces.this.nullOr$default$1[Array[Byte]])((ClassTag.apply[Array[Byte]](scala.runtime.ScalaRunTime.arrayClass(classOf[scala.Byte])): scala.reflect.ClassTag[Array[Byte]]))
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          1104
        </td>
        <td>
          6773
          -
          6794
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Array[Byte]](ResultInterfaces.this.nullOr$default$1[Array[Byte]])((ClassTag.apply[Array[Byte]](scala.runtime.ScalaRunTime.arrayClass(classOf[scala.Byte])): scala.reflect.ClassTag[Array[Byte]]))
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          1105
        </td>
        <td>
          6822
          -
          6822
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr$default$1[Byte]
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          1106
        </td>
        <td>
          6816
          -
          6830
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Byte](ResultInterfaces.this.nullOr$default$1[Byte])((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          1107
        </td>
        <td>
          6816
          -
          6830
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Byte](ResultInterfaces.this.nullOr$default$1[Byte])((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          1108
        </td>
        <td>
          6859
          -
          6859
        </td>
        <td>
          TypeApply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr$default$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr$default$1[Short]
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          1109
        </td>
        <td>
          6853
          -
          6868
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Short](ResultInterfaces.this.nullOr$default$1[Short])((ClassTag.Short: scala.reflect.ClassTag[Short]))
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          1110
        </td>
        <td>
          6853
          -
          6868
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Short](ResultInterfaces.this.nullOr$default$1[Short])((ClassTag.Short: scala.reflect.ClassTag[Short]))
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          1111
        </td>
        <td>
          6917
          -
          7015
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateToDays( (java.time.LocalDate) &quot;, &quot; )&quot;).s(path)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          1112
        </td>
        <td>
          6896
          -
          7016
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Int](((path: String) =&gt; scala.StringContext.apply(&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateToDays( (java.time.LocalDate) &quot;, &quot; )&quot;).s(path)))((ClassTag.Int: scala.reflect.ClassTag[Int]))
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          1113
        </td>
        <td>
          6896
          -
          7016
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Int](((path: String) =&gt; scala.StringContext.apply(&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateToDays( (java.time.LocalDate) &quot;, &quot; )&quot;).s(path)))((ClassTag.Int: scala.reflect.ClassTag[Int]))
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          1114
        </td>
        <td>
          7071
          -
          7179
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateTimeToMicros( (java.time.LocalDateTime) &quot;, &quot; )&quot;).s(path)
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          1115
        </td>
        <td>
          7049
          -
          7180
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Long](((path: String) =&gt; scala.StringContext.apply(&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateTimeToMicros( (java.time.LocalDateTime) &quot;, &quot; )&quot;).s(path)))((ClassTag.Long: scala.reflect.ClassTag[Long]))
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          1116
        </td>
        <td>
          7049
          -
          7180
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ResultInterfaces.this.nullOr[Long](((path: String) =&gt; scala.StringContext.apply(&quot;org.apache.spark.sql.catalyst.util.DateTimeUtils.localDateTimeToMicros( (java.time.LocalDateTime) &quot;, &quot; )&quot;).s(path)))((ClassTag.Long: scala.reflect.ClassTag[Long]))
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          1117
        </td>
        <td>
          7239
          -
          7314
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;org.apache.spark.sql.types.Decimal.apply( (java.math.BigDecimal) &quot;, &quot; )&quot;).s(path)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          1118
        </td>
        <td>
          7214
          -
          7315
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[org.apache.spark.sql.types.Decimal](((path: String) =&gt; scala.StringContext.apply(&quot;org.apache.spark.sql.types.Decimal.apply( (java.math.BigDecimal) &quot;, &quot; )&quot;).s(path)))((ClassTag.apply[org.apache.spark.sql.types.Decimal](classOf[org.apache.spark.sql.types.Decimal]): scala.reflect.ClassTag[org.apache.spark.sql.types.Decimal]))
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          1119
        </td>
        <td>
          7214
          -
          7315
        </td>
        <td>
          Block
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.nullOr
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.nullOr[org.apache.spark.sql.types.Decimal](((path: String) =&gt; scala.StringContext.apply(&quot;org.apache.spark.sql.types.Decimal.apply( (java.math.BigDecimal) &quot;, &quot; )&quot;).s(path)))((ClassTag.apply[org.apache.spark.sql.types.Decimal](classOf[org.apache.spark.sql.types.Decimal]): scala.reflect.ClassTag[org.apache.spark.sql.types.Decimal]))
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          1137
        </td>
        <td>
          7352
          -
          8459
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((ctx: org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext, pathName: String, pathNameIsNull: String) =&gt; {
  val expr: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode = com.sparkutils.dmn.kogito.types.Arrays.exprCode(classOf[org.apache.spark.sql.catalyst.util.GenericArrayData], ctx);
  val iar: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;ar&quot;, classOf[java.util.List]);
  val i: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;i&quot;, classOf[scala.Int]);
  val arrRes: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;arr&quot;, classOf[[Ljava.lang.Object;]);
  val typCode: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode = ResultInterfaces.this.forTypeCodeGen(typ).forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;[&quot;, &quot;]&quot;).s(arrRes, i), codegen.this.ExprValue.exprValueToString(expr.isNull));
  expr.copy(org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.GenericArrayData &quot;, &quot; = null;\n            java.util.List &quot;, &quot; = (java.util.List&lt;Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = &quot;, &quot;.toArray();\n\n              for (int &quot;, &quot; = 0; &quot;, &quot; &lt; &quot;, &quot;.length; &quot;, &quot;++) {\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n              }\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;);\n            }\n            &quot;)).code(expr.value, iar, pathName, expr.isNull, pathNameIsNull, expr.isNull, arrRes, iar, i, i, arrRes, i, typCode.code, arrRes, i, typCode.value, expr.value, arrRes), expr.copy$default$2, expr.copy$default$3)
})
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          1120
        </td>
        <td>
          7440
          -
          7479
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.Arrays.exprCode
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.dmn.kogito.types.Arrays.exprCode(classOf[org.apache.spark.sql.catalyst.util.GenericArrayData], ctx)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          1121
        </td>
        <td>
          7499
          -
          7550
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;ar&quot;, classOf[java.util.List])
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          1122
        </td>
        <td>
          7568
          -
          7604
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;i&quot;, classOf[scala.Int])
        </td>
      </tr><tr>
        <td>
          174
        </td>
        <td>
          1123
        </td>
        <td>
          7627
          -
          7675
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;arr&quot;, classOf[[Ljava.lang.Object;])
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          1124
        </td>
        <td>
          7732
          -
          7746
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;[&quot;, &quot;]&quot;).s(arrRes, i)
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          1125
        </td>
        <td>
          7748
          -
          7759
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          1126
        </td>
        <td>
          7748
          -
          7759
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprValue.exprValueToString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          codegen.this.ExprValue.exprValueToString(expr.isNull)
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          1127
        </td>
        <td>
          7699
          -
          7760
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen.forPath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forTypeCodeGen(typ).forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;[&quot;, &quot;]&quot;).s(arrRes, i), codegen.this.ExprValue.exprValueToString(expr.isNull))
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          1136
        </td>
        <td>
          7770
          -
          8451
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.copy(org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.GenericArrayData &quot;, &quot; = null;\n            java.util.List &quot;, &quot; = (java.util.List&lt;Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = &quot;, &quot;.toArray();\n\n              for (int &quot;, &quot; = 0; &quot;, &quot; &lt; &quot;, &quot;.length; &quot;, &quot;++) {\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n              }\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;);\n            }\n            &quot;)).code(expr.value, iar, pathName, expr.isNull, pathNameIsNull, expr.isNull, arrRes, iar, i, i, arrRes, i, typCode.code, arrRes, i, typCode.value, expr.value, arrRes), expr.copy$default$2, expr.copy$default$3)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          1128
        </td>
        <td>
          7810
          -
          8441
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.GenericArrayData &quot;, &quot; = null;\n            java.util.List &quot;, &quot; = (java.util.List&lt;Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = &quot;, &quot;.toArray();\n\n              for (int &quot;, &quot; = 0; &quot;, &quot; &lt; &quot;, &quot;.length; &quot;, &quot;++) {\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n              }\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;);\n            }\n            &quot;)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          1135
        </td>
        <td>
          7810
          -
          8441
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.GenericArrayData &quot;, &quot; = null;\n            java.util.List &quot;, &quot; = (java.util.List&lt;Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = &quot;, &quot;.toArray();\n\n              for (int &quot;, &quot; = 0; &quot;, &quot; &lt; &quot;, &quot;.length; &quot;, &quot;++) {\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n              }\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;);\n            }\n            &quot;)).code(expr.value, iar, pathName, expr.isNull, pathNameIsNull, expr.isNull, arrRes, iar, i, i, arrRes, i, typCode.code, arrRes, i, typCode.value, expr.value, arrRes)
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          1129
        </td>
        <td>
          7884
          -
          7894
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.value
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          1130
        </td>
        <td>
          7995
          -
          8006
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          1131
        </td>
        <td>
          8068
          -
          8079
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          1132
        </td>
        <td>
          8238
          -
          8250
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          typCode.code
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          1133
        </td>
        <td>
          8284
          -
          8297
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          typCode.value
        </td>
      </tr><tr>
        <td>
          193
        </td>
        <td>
          1134
        </td>
        <td>
          8332
          -
          8342
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.value
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          1164
        </td>
        <td>
          8495
          -
          10630
        </td>
        <td>
          Function
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.$anonfun
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ((ctx: org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext, pathName: String, pathNameIsNull: String) =&gt; {
  val expr: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode = com.sparkutils.dmn.kogito.types.Arrays.exprCode(classOf[org.apache.spark.sql.catalyst.util.ArrayBasedMapData], ctx);
  val map: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;map&quot;, classOf[java.util.Map]);
  val i: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;i&quot;, classOf[scala.Int]);
  val entry: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;entry&quot;, classOf[java.util.Map$Entry]);
  val typCodeK: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode = ResultInterfaces.this.forTypeCodeGen(k).forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.getKey()&quot;).s(entry), codegen.this.ExprValue.exprValueToString(expr.isNull));
  val typCodeV: org.apache.spark.sql.catalyst.expressions.codegen.ExprCode = ResultInterfaces.this.forTypeCodeGen(v).forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.getValue()&quot;).s(entry), codegen.this.ExprValue.exprValueToString(expr.isNull));
  val arrKeyRes: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;arrKey&quot;, classOf[[Ljava.lang.Object;]);
  val arrValueRes: org.apache.spark.sql.catalyst.expressions.codegen.VariableValue = ctx.freshVariable(&quot;arrValue&quot;, classOf[[Ljava.lang.Object;]);
  val itr: String = ctx.freshName(&quot;itr&quot;);
  expr.copy(org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.ArrayBasedMapData &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              java.util.Iterator&lt;java.util.Map.Entry&lt;String, Object&gt;&gt; &quot;, &quot; = &quot;, &quot;.entrySet().iterator();\n              int &quot;, &quot; = 0;\n              while (&quot;, &quot;.hasNext()){\n                java.util.Map.Entry&lt;String, Object&gt; &quot;, &quot; = (java.util.Map.Entry&lt;String, Object&gt;) &quot;, &quot;.next();\n                &quot;, &quot;\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot; = &quot;, &quot; + 1;\n              }\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;),\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;)\n                );\n            }\n            &quot;)).code(expr.value, map, pathName, expr.isNull, pathNameIsNull, expr.isNull, arrKeyRes, map, arrValueRes, map, itr, map, i, itr, entry, itr, typCodeK.code, typCodeV.code, arrKeyRes, i, typCodeK.value, arrValueRes, i, typCodeV.value, i, i, expr.value, arrKeyRes, arrValueRes), expr.copy$default$2, expr.copy$default$3)
})
        </td>
      </tr><tr>
        <td>
          200
        </td>
        <td>
          1138
        </td>
        <td>
          8583
          -
          8624
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.Arrays.exprCode
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.sparkutils.dmn.kogito.types.Arrays.exprCode(classOf[org.apache.spark.sql.catalyst.util.ArrayBasedMapData], ctx)
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          1139
        </td>
        <td>
          8644
          -
          8703
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;map&quot;, classOf[java.util.Map])
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          1140
        </td>
        <td>
          8721
          -
          8757
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;i&quot;, classOf[scala.Int])
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          1141
        </td>
        <td>
          8779
          -
          8846
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;entry&quot;, classOf[java.util.Map$Entry])
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          1142
        </td>
        <td>
          8902
          -
          8920
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;.getKey()&quot;).s(entry)
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          1143
        </td>
        <td>
          8922
          -
          8933
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          1144
        </td>
        <td>
          8922
          -
          8933
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprValue.exprValueToString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          codegen.this.ExprValue.exprValueToString(expr.isNull)
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          1145
        </td>
        <td>
          8871
          -
          8934
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen.forPath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forTypeCodeGen(k).forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.getKey()&quot;).s(entry), codegen.this.ExprValue.exprValueToString(expr.isNull))
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          1146
        </td>
        <td>
          8989
          -
          9009
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;.getValue()&quot;).s(entry)
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          1147
        </td>
        <td>
          9011
          -
          9022
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          1148
        </td>
        <td>
          9011
          -
          9022
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprValue.exprValueToString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          codegen.this.ExprValue.exprValueToString(expr.isNull)
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          1149
        </td>
        <td>
          8958
          -
          9023
        </td>
        <td>
          Apply
        </td>
        <td>
          com.sparkutils.dmn.kogito.types.ResultInterfaces.GetterCodeGen.forPath
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ResultInterfaces.this.forTypeCodeGen(v).forPath(ctx, scala.StringContext.apply(&quot;&quot;, &quot;.getValue()&quot;).s(entry), codegen.this.ExprValue.exprValueToString(expr.isNull))
        </td>
      </tr><tr>
        <td>
          211
        </td>
        <td>
          1150
        </td>
        <td>
          9049
          -
          9100
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;arrKey&quot;, classOf[[Ljava.lang.Object;])
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          1151
        </td>
        <td>
          9127
          -
          9180
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshVariable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshVariable(&quot;arrValue&quot;, classOf[[Ljava.lang.Object;])
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          1152
        </td>
        <td>
          9200
          -
          9220
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.freshName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ctx.freshName(&quot;itr&quot;)
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          1163
        </td>
        <td>
          9335
          -
          10622
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.copy(org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.ArrayBasedMapData &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              java.util.Iterator&lt;java.util.Map.Entry&lt;String, Object&gt;&gt; &quot;, &quot; = &quot;, &quot;.entrySet().iterator();\n              int &quot;, &quot; = 0;\n              while (&quot;, &quot;.hasNext()){\n                java.util.Map.Entry&lt;String, Object&gt; &quot;, &quot; = (java.util.Map.Entry&lt;String, Object&gt;) &quot;, &quot;.next();\n                &quot;, &quot;\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot; = &quot;, &quot; + 1;\n              }\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;),\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;)\n                );\n            }\n            &quot;)).code(expr.value, map, pathName, expr.isNull, pathNameIsNull, expr.isNull, arrKeyRes, map, arrValueRes, map, itr, map, i, itr, entry, itr, typCodeK.code, typCodeV.code, arrKeyRes, i, typCodeK.value, arrValueRes, i, typCodeV.value, i, i, expr.value, arrKeyRes, arrValueRes), expr.copy$default$2, expr.copy$default$3)
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          1153
        </td>
        <td>
          9375
          -
          10612
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.ArrayBasedMapData &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              java.util.Iterator&lt;java.util.Map.Entry&lt;String, Object&gt;&gt; &quot;, &quot; = &quot;, &quot;.entrySet().iterator();\n              int &quot;, &quot; = 0;\n              while (&quot;, &quot;.hasNext()){\n                java.util.Map.Entry&lt;String, Object&gt; &quot;, &quot; = (java.util.Map.Entry&lt;String, Object&gt;) &quot;, &quot;.next();\n                &quot;, &quot;\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot; = &quot;, &quot; + 1;\n              }\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;),\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;)\n                );\n            }\n            &quot;)
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          1162
        </td>
        <td>
          9375
          -
          10612
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.catalyst.expressions.codegen.Block.BlockHelper(scala.StringContext.apply(&quot;\n            org.apache.spark.sql.catalyst.util.ArrayBasedMapData &quot;, &quot; = null;\n            java.util.Map &quot;, &quot; = (java.util.Map&lt;String, Object&gt;)&quot;, &quot;;\n            boolean &quot;, &quot; = false;\n            if (&quot;, &quot;) {\n              &quot;, &quot; = true;\n            } else {\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              Object[] &quot;, &quot; = new Object[&quot;, &quot;.size()];\n              java.util.Iterator&lt;java.util.Map.Entry&lt;String, Object&gt;&gt; &quot;, &quot; = &quot;, &quot;.entrySet().iterator();\n              int &quot;, &quot; = 0;\n              while (&quot;, &quot;.hasNext()){\n                java.util.Map.Entry&lt;String, Object&gt; &quot;, &quot; = (java.util.Map.Entry&lt;String, Object&gt;) &quot;, &quot;.next();\n                &quot;, &quot;\n                &quot;, &quot;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot;[&quot;, &quot;] = &quot;, &quot;;\n                &quot;, &quot; = &quot;, &quot; + 1;\n              }\n\n              &quot;, &quot; = new org.apache.spark.sql.catalyst.util.ArrayBasedMapData(\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;),\n                new org.apache.spark.sql.catalyst.util.GenericArrayData(&quot;, &quot;)\n                );\n            }\n            &quot;)).code(expr.value, map, pathName, expr.isNull, pathNameIsNull, expr.isNull, arrKeyRes, map, arrValueRes, map, itr, map, i, itr, entry, itr, typCodeK.code, typCodeV.code, arrKeyRes, i, typCodeK.value, arrValueRes, i, typCodeV.value, i, i, expr.value, arrKeyRes, arrValueRes)
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          1154
        </td>
        <td>
          9450
          -
          9460
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.value
        </td>
      </tr><tr>
        <td>
          221
        </td>
        <td>
          1155
        </td>
        <td>
          9567
          -
          9578
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          1156
        </td>
        <td>
          9640
          -
          9651
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.isNull
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.isNull
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          1157
        </td>
        <td>
          10105
          -
          10118
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          typCodeK.code
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          1158
        </td>
        <td>
          10138
          -
          10151
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.code
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          typCodeV.code
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          1159
        </td>
        <td>
          10188
          -
          10202
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          typCodeK.value
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          1160
        </td>
        <td>
          10242
          -
          10256
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          typCodeV.value
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          1161
        </td>
        <td>
          10321
          -
          10331
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.codegen.ExprCode.value
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          expr.value
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          1165
        </td>
        <td>
          10645
          -
          10732
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new com.sparkutils.dmn.DMNException(scala.StringContext.apply(&quot;Could not load Kogito Result Provider for dataType &quot;, &quot;&quot;).s(dataType))
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          1166
        </td>
        <td>
          10645
          -
          10732
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new com.sparkutils.dmn.DMNException(scala.StringContext.apply(&quot;Could not load Kogito Result Provider for dataType &quot;, &quot;&quot;).s(dataType))
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>